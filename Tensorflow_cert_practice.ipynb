{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JordanTheDodger/DL_Fun-models/blob/main/Tensorflow_cert_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "k5fkUXq4_AH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet tensorflow\n",
        "!pip install --quiet tf-keras~=2.16\n",
        "# !pip install --quiet tensorflow==2.15.1\n",
        "#install only if running BERT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2mqXS4W2S9F",
        "outputId": "a2944aed-7baf-42da-8ef7-cd6769e8991f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.8/286.8 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet tensorflow_text\n",
        "#install only if running BERT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez4J_vRPzKsH",
        "outputId": "f34c49b8-4ff7-4e88-e237-571b5d48b72d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/5.2 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/5.2 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip list -v\n",
        "SAVE_DIR = \"certification_model_logs\""
      ],
      "metadata": {
        "id": "6ij2u_vg2uBW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-t6G6jGcP3Cu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: Problem while running BERT, format err\n",
        "`RuntimeError: Op type not registered 'CaseFoldUTF8' in binary running on d9dcdc0ab727`\n",
        "\n",
        "- Install tf-keras via pip install tf-keras~=2.16\n",
        "\n",
        "- To switch tf.keras to use Keras 2 (tf-keras), set the environment variable TF_USE_LEGACY_KERAS=1 directly or in your python program with import os;`os.environ[\"TF_USE_LEGACY_KERAS\"]=\"1\"`. Please note that this will set it for all packages in your Python runtime program\n",
        "\n",
        "- Change the keras import: replace import tensorflow.keras as keras or import keras with `import tf_keras as keras`. Update any tf.keras references to keras.\n"
      ],
      "metadata": {
        "id": "UQT3GMQo6-b4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# os.environ[\"TF_USE_LEGACY_KERA\"]=\"1\""
      ],
      "metadata": {
        "id": "CiMyMH7V7kOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2H7NCC3PqqX",
        "outputId": "fec70849-4da4-449d-cb88-f7542eb30773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.16.1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import tf_keras as keras\n",
        "import tensorflow_text\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer # covert text into numbers using TFIDF formula\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline # Pipeline perform steps in order just like Keras sequential model"
      ],
      "metadata": {
        "id": "KmKck8mpD8xS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRPJOzq5Pp8E",
        "outputId": "935a685f-7264-46c6-a4db-bad0797eb1db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DL_Helper_functions'...\n",
            "remote: Enumerating objects: 57, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 57 (delta 22), reused 5 (delta 2), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (57/57), 35.84 KiB | 749.00 KiB/s, done.\n",
            "Resolving deltas: 100% (22/22), done.\n"
          ]
        }
      ],
      "source": [
        "#get helper finctions\n",
        "!git clone https://github.com/JordanTheDodger/DL_Helper_functions.git\n",
        "import sys\n",
        "#sys.path\n",
        "sys.path.insert(0,\"/content/DL_Helper_functions/helper_functions.py\")\n",
        "# importing helper functions\n",
        "from DL_Helper_functions import helper_functions as hf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj4idgolP_yw",
        "outputId": "45749320-6b83-46c5-d106-78026f265f43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(train_images,train_labels), (test_imgaes,test_labels) = datasets.fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-OC997nQDCp",
        "outputId": "0dee0be9-206d-4258-87d7-887aa44c24bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# pre-process data (normalize valuse b/w 0 & 1)\n",
        "train_images.shape,test_imgaes.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltFk35zcRhea"
      },
      "source": [
        "## packages and libs\n",
        "- `tensorflow`\n",
        "- `keras`\n",
        "\n",
        "> Image Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4ucbdTJSO5r"
      },
      "source": [
        "- Define Convolutional neural networks with Conv2D and pooling layers.\n",
        "- Build and train models to process real-world image datasets.\n",
        "- Understand how to use convolutions to improve your neural network.\n",
        "- Use real-world images in different shapes and sizes..\n",
        "- Use image augmentation to prevent overfitting.\n",
        "- Use ImageDataGenerator.\n",
        "- Understand how ImageDataGenerator labels images based on the directory structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NRIb06FpRRhF"
      },
      "outputs": [],
      "source": [
        "# Binary classification\n",
        "# build model\n",
        "# compile model\n",
        "# fit model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ss2X9AtSRZKi"
      },
      "outputs": [],
      "source": [
        "# Multi-class classification\n",
        "# build model\n",
        "# compile model\n",
        "# fit model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYUbu3soRcQk"
      },
      "source": [
        "> Natural Language Processing (NLP)\n",
        "- Build natural language processing systems using TensorFlow.\n",
        "- Prepare text to use in TensorFlow models.\n",
        "- Build models that identify the category of a piece of text using binary categorization\n",
        "- Build models that identify the category of a piece of text using multi-class categorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHuKGcNzPG-U",
        "outputId": "5f491b8c-cb88-4e82-f3a9-82237aff6236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-18 17:44:33--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.2.207, 2607:f8b0:4023:c0b::cf, 2607:f8b0:4023:c0d::cf\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.2.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-03-18 17:44:33 (108 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#load dataset\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "hf.unzip_data(\"nlp_getting_started.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0seLrMP_P-e7",
        "outputId": "a565f9a8-75f6-4833-adcb-e8213371d0da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "#shuffle train data\n",
        "train_df.sample(frac=2,random_state=42,replace=True) #shuffling 20% data\n",
        "train_df.target.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DOSX2vqRHbr",
        "outputId": "1edecdb4-37ab-4b2b-c55c-71704b48b30d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# sample size\n",
        "len(train_df), len(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_O6q8VfR_Yl",
        "outputId": "336eb4bd-4f99-42f8-ca80-feba29214d4a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#create train and test split\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df[\"text\"].to_numpy(),\n",
        "                                                                            train_df[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1,#use 10% traindata for validation\n",
        "                                                                            random_state=852)\n",
        "\n",
        "len(train_sentences),len(train_labels),len(val_sentences),len(val_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXQ7xeO4z4cn"
      },
      "source": [
        "**Steps for getting text ready for NLP model**\n",
        "- create `TextVectorization layer` using `keras.layers.TextVectorization`\n",
        "> * `max_tokens,output_sequence_length,output_mode=int`\n",
        "> * batch training dataset `tensorflow.data.Dataset.from_tensor_slices(train_text).batch(128).prefetch(tensorflow.data.AUTOTUNE)`\n",
        "> * fit it to training text `text_vectorizer.adapt(train_text)`\n",
        "> * test **text_vectorizer** to create `tokens`. eg: pass a random sentence to `text_vectorizer`\n",
        "> * `text_vectorizer.get_vocabulary()` to get unique set of words\n",
        "\n",
        "- create an Embedding using `keras.layers.Embedding`\n",
        "> - `input_dim` (input shape) - *size of voacbulary*\n",
        "> - `output_dim` (output shape, need to be divisble by 8) - *length of vector for each word*\n",
        "> - `embeddings_initalizer=\"uniform\"`\n",
        "> * `input_length` - *maximum length of a sequence*\n",
        "> * test embedding on any tokenized text `embedding(text_vectorizer[sample_text])`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ozlDZ_npRkJD"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras.layers import Embedding\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z9_OWpWSAOJ",
        "outputId": "170d3a6e-23aa-4726-d923-49381afd5932"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary:102128\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# find avg # of tokens(words) in train tweets [avg =sum/total]\n",
        "vocab = []\n",
        "for i in train_sentences:\n",
        "  vocab.append(len(i.split()))\n",
        "print(f'Vocabulary:{sum(vocab)}')\n",
        "round(sum(vocab)/len(train_sentences)) #avg length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeQpP_ZMS3Sx",
        "outputId": "e10da0a6-453d-4d28-913a-8fbca71cf489"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique words in vocab:10000\n"
          ]
        }
      ],
      "source": [
        "MAX_VOCAB_LENGTH = 10000\n",
        "MAX_LENGTH = 15\n",
        "\n",
        "# create TextVectorization layer\n",
        "text_vectorizer = TextVectorization(max_tokens=MAX_VOCAB_LENGTH,\n",
        "                                    output_mode='int',\n",
        "                                    output_sequence_length=MAX_LENGTH)\n",
        "\n",
        "# fit text vectorizer to train data\n",
        "text_vectorizer.adapt(train_sentences)\n",
        "\n",
        "# get unique set of words\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f'Number of unique words in vocab:{len(words_in_vocab)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Gw4hjCKWIIp",
        "outputId": "530d0090-d1dc-41a0-b1f4-5c99f0ea6402"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 512), dtype=float32, numpy=\n",
              "array([[[ 0.03999953,  0.00197522,  0.01958085, ...,  0.01811798,\n",
              "         -0.04344773, -0.00250548],\n",
              "        [ 0.03999953,  0.00197522,  0.01958085, ...,  0.01811798,\n",
              "         -0.04344773, -0.00250548],\n",
              "        [ 0.00368253,  0.04646606,  0.01075722, ...,  0.0230674 ,\n",
              "         -0.0057562 , -0.00296017],\n",
              "        ...,\n",
              "        [ 0.00368253,  0.04646606,  0.01075722, ...,  0.0230674 ,\n",
              "         -0.0057562 , -0.00296017],\n",
              "        [-0.00347497, -0.03550144,  0.02382647, ...,  0.00540742,\n",
              "          0.04338136, -0.01229452],\n",
              "        [-0.01632041, -0.00127094,  0.0365544 , ..., -0.00282677,\n",
              "          0.03479505, -0.04723123]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# create Embedding\n",
        "embedding = Embedding(input_dim=MAX_VOCAB_LENGTH,\n",
        "                                   output_dim=512,\n",
        "                                   embeddings_initializer=\"uniform\",\n",
        "                                   input_length=MAX_LENGTH)\n",
        "# test embedding\n",
        "random_sentence = random.choice(train_sentences)\n",
        "test_embedding = embedding(text_vectorizer([random_sentence]))\n",
        "test_embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJGBhZvuYyfa"
      },
      "source": [
        "# Conv 1D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MltX3kcreaO8",
        "outputId": "d2bea316-5404-4770-9428-9acd528ba681"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 512]), TensorShape([1, 15, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# testing embedding, conv1d and max pool layers to inspect shape information\n",
        "conv_1d = keras.layers.Conv1D(filters=32,\n",
        "                              kernel_size=5,\n",
        "                              activation=\"relu\",\n",
        "                              padding=\"same\")\n",
        "conv_1d_op = conv_1d(test_embedding)\n",
        "max_pool = keras.layers.GlobalMaxPool1D()\n",
        "max_pool_op = max_pool(conv_1d_op)\n",
        "# shape of conv1d and max pool layers\n",
        "test_embedding.shape, conv_1d_op.shape, max_pool_op.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KCFu-guYnd5O"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Po_kqSXLhLG8",
        "outputId": "5ad91356-3a2c-421e-a583-86e0f7b91404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Conv_1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVe  (None, 15)                0         \n",
            " ctorization)                                                    \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 512)           5120000   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 3, 64)             327744    \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Gl  (None, 64)                0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5451969 (20.80 MB)\n",
            "Trainable params: 5451969 (20.80 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# model 5 using Functional API\n",
        "# build model\n",
        "inputs = keras.layers.Input(shape=(1,),dtype=tf.string) #inputting 1 sequence at a time\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = keras.layers.Conv1D(filters=64,kernel_size=10,strides=2,activation=\"relu\",padding=\"valid\")(x)\n",
        "x = keras.layers.GlobalMaxPool1D()(x)\n",
        "x = keras.layers.Dense(64,activation=\"relu\")(x)\n",
        "outputs = keras.layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "conv1d_model = keras.Model(inputs,outputs,name=\"Conv_1D\")\n",
        "\n",
        "# compile model\n",
        "conv1d_model.compile(loss=\"binary_crossentropy\",\n",
        "                     optimizer=tf.keras.optimizers.Adam(),\n",
        "                     metrics=[\"accuracy\"])\n",
        "# summary\n",
        "conv1d_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKqB8e3Mp8Uf"
      },
      "source": [
        "# create batch train and val sets\n",
        "train_char_dataset = tf_data.Dataset.batch(128).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvIfNEU4qPGc",
        "outputId": "8e6556de-aaf7-4b3c-e310-85ddd8484e7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 0.45769, saving model to certification_model_logs/Conv_1D\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.45769\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.45769\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.45769\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.45769\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.45769\n"
          ]
        }
      ],
      "source": [
        "#fit model\n",
        "import os\n",
        "conv1d_model_history = conv1d_model.fit(train_sentences,\n",
        "                                        train_labels,\n",
        "                                        epochs=100,\n",
        "                                        validation_data=(val_sentences,val_labels),\n",
        "                                        verbose=0,\n",
        "                                        callbacks=[keras.callbacks.ModelCheckpoint(filepath=os.path.join(SAVE_DIR,conv1d_model.name),save_best_only=True,verbose=1),\n",
        "                                                   keras.callbacks.EarlyStopping(monitor='val_loss',patience=5)])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9yG69BPVIYV"
      },
      "source": [
        "> - `tf.keras.callbacks.ModelCheckpoint` allow saving best performing checkpoint during model training.\n",
        "> - `tf.keras.callbacks.EarlyStopping` allow halting model training once validation loss has stopped improving\n",
        "> - Use them together to save model's best performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ixov3qM6U_B4",
        "outputId": "01c56af5-9bef-479a-9f1c-3c532dc26306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "# finding best performing epoch\n",
        "val_acc_per_epoch = conv1d_model_history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print(best_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5TXdux9ro-_",
        "outputId": "954ef744-dc99-489d-e1da-5b64b1284aef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 0., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# make predictions\n",
        "conv1d_preds = conv1d_model.predict(val_sentences)\n",
        "#squeeze extra dim\n",
        "conv1d_preds = tf.squeeze(tf.round(conv1d_preds))\n",
        "conv1d_preds[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts6RqUpntdwG",
        "outputId": "82fc4b83-3a51-4412-f203-04288fd6288a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.11548556430446,\n",
              " 'precision': 0.7604419817893134,\n",
              " 'recall': 0.7611548556430446,\n",
              " 'f1': 0.7579009427277313}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# evaulte model predictions\n",
        "conv1d_evaluation = hf.calculate_results(y_true=val_labels,y_pred=conv1d_preds)\n",
        "conv1d_evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyzYYdRkuCZT"
      },
      "source": [
        "# Using Pre-trained word embeddings **GLOVE**\n",
        "\n",
        "[Glove](https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ_V2GNCuLa_"
      },
      "source": [
        "- data is 20,000 messages with 20 different topic categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qImJ_j1ht0fU",
        "outputId": "0381b849-04d5-436c-a663-960a93a7f1fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\n",
            "17329808/17329808 [==============================] - 21s 1us/step\n"
          ]
        }
      ],
      "source": [
        "# get data\n",
        "data_path = keras.utils.get_file(\n",
        "    \"news20.tar.gz\",\n",
        "    \"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\",\n",
        "    untar=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlcQbXV-t6Bb",
        "outputId": "001caab5-7366-4cb4-f981-2dbf1a5baef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of directories: 20\n",
            "Directory names: ['comp.windows.x', 'comp.sys.ibm.pc.hardware', 'alt.atheism', 'rec.sport.hockey', 'talk.politics.misc', 'talk.politics.guns', 'talk.politics.mideast', 'sci.crypt', 'sci.med', 'misc.forsale', 'sci.space', 'rec.sport.baseball', 'sci.electronics', 'rec.autos', 'rec.motorcycles', 'comp.sys.mac.hardware', 'comp.graphics', 'soc.religion.christian', 'comp.os.ms-windows.misc', 'talk.religion.misc']\n",
            "Number of files in rec.motorcycles: 1000\n",
            "Some example filenames: ['104704', '103192', '105142', '104692', '105108']\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "import os\n",
        "import tensorflow.data as tf_data\n",
        "#inspect data\n",
        "data_dir = pathlib.Path(data_path).parent / \"20_newsgroup\"\n",
        "dirnames = os.listdir(data_dir)\n",
        "print(\"Number of directories:\", len(dirnames))\n",
        "print(\"Directory names:\", dirnames)\n",
        "\n",
        "fnames = os.listdir(data_dir / \"rec.motorcycles\")\n",
        "print(\"Number of files in rec.motorcycles:\", len(fnames))\n",
        "print(\"Some example filenames:\", fnames[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoBW4SQKwYJn",
        "outputId": "eba19cb3-ab08-495f-b3ff-1caddf46e635"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files in sci.electronics: 1000\n",
            "Some example filenames: ['53550', '54262', '53546', '53515', '53583']\n"
          ]
        }
      ],
      "source": [
        "fnames = os.listdir(data_dir / \"sci.electronics\")\n",
        "print(\"Number of files in sci.electronics:\", len(fnames))\n",
        "print(\"Some example filenames:\", fnames[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kt2yM1Ruofr",
        "outputId": "a2adcafe-60e8-46fb-d679-d3033eaa2400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xref: cantaloupe.srv.cs.cmu.edu rec.motorcycles:105097 rec.motorcycles.racing:2044\n",
            "Path: cantaloupe.srv.cs.cmu.edu!rochester!udel!gatech!emory!swrinde!sdd.hp.com!elroy.jpl.nasa.gov!usc!cs.utexas.edu!uunet!olivea!pagesat!spssig.spss.com!news.oc.com!ccwf.cc.utexas.edu!lusky\n",
            "From: lusky@ccwf.cc.utexas.edu (Jonathan R. Lusky)\n",
            "Newsgroups: tx.motorcycles,rec.motorcycles,rec.motorcycles.racing\n",
            "Subject: Kawasaki ZX-6 engine needed\n",
            "Message-ID: <1993Apr17.082542.16319@ra.oc.com>\n",
            "Date: 17 Apr 93 08:25:42 GMT\n",
            "Sender: usenet@ra.oc.com\n",
            "Reply-To: lusky@ccwf.cc.utexas.edu (Jonathan R. Lusky)\n",
            "Followup-To: lusky@ccwf.cc.utexas.edu\n",
            "Distribution: usa\n",
            "Organization: UT SAE / Longhorn Racing Team\n",
            "Lines: 14\n",
            "Originator: lusky@sylvester.cc.utexas.edu\n",
            "\n",
            "I'm looking for a 1990-91 Kawasaki ZX-6 engine.  Just the engine,\n",
            "no intake, exhaust, ignition, etc.  Preferably in the central texas\n",
            "area, but we haven't had much luck around here so we'll take whatever we\n",
            "can get.  Please reply via mail or call (512) 471-5399 if you have one\n",
            "(or more...  really need a spare).\n",
            "\n",
            "Thanx\n",
            "\n",
            "-- \n",
            "--=< Jonathan Lusky ----- lusky@ccwf.cc.utexas.edu >=-- \n",
            "    \\ \"Turbos are nice, but I'd rather be blown!\" /\n",
            "     \\    89 Jeep Wrangler - 258/for sale!       / \n",
            "      \\        79 Rx-7 - 12A/Holley 4bbl        / \n",
            "       \\________67 Camaro RS - 350/4spd________/ \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# reading an example\n",
        "print(open((data_dir/\"rec.motorcycles\"/\"105097\")).read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSG7AZCZwkQf",
        "outputId": "60cab79e-5eb1-42ef-b6f9-2ed94afb04cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!noc.near.net!howland.reston.ans.net!zaphod.mps.ohio-state.edu!cs.utexas.edu!tamsun.tamu.edu!sigma.tamu.edu!avm1993\n",
            "From: avm1993@sigma.tamu.edu (MAMISHEV, ALEXANDER VALENTINO)\n",
            "Newsgroups: sci.electronics\n",
            "Subject: digital voltmeter - how does it work?\n",
            "Date: 20 Apr 1993 18:11 CST\n",
            "Organization: Texas A&M University, Academic Computing Services\n",
            "Lines: 34\n",
            "Distribution: world\n",
            "Message-ID: <20APR199318114218@sigma.tamu.edu>\n",
            "NNTP-Posting-Host: sigma.tamu.edu\n",
            "News-Software: VAX/VMS VNEWS 1.41    \n",
            "\n",
            "     Hello, \n",
            "\n",
            "   Let me introduce a problem:\n",
            "\n",
            "   When I measure a sinusoidal wave (voltage) with a digital voltmeter, using \n",
            "AC mode, my output is an rms value (a peak value over 2 squared). / Right? / \n",
            "   When I measure a square wave in the same mode (AC), my output is equal \n",
            "to a peak value, actually, to the upper flat boundary of the wave.\n",
            "   I assumed, that a digital voltmeter makes some kind of integration of the \n",
            "input value, and divides it over the wave period. / Right?/\n",
            "   Now, I used it to measure the same  square wave as above, but distorted \n",
            "by high-frequency harmonics. Ideally, output should be the same, but...\n",
            "The output value was only about 10% of the previous one! \n",
            "   Why? What is the nature of this output value? What does the voltmeter \n",
            "actually measure? And what does it show?  \n",
            "\n",
            "   Related question (less important to me):\n",
            "   What are advantages and disadvantages of digital voltmeters to compare with \n",
            "analog ones? \n",
            "\n",
            "   Thank you for your attention, you could mail me your opinion at\n",
            "avm1993@zeus.tamu.edu or open a discussion here. I would appreciate either \n",
            "way.\n",
            "\n",
            "\n",
            "Alexander V. Mamishev\n",
            "\n",
            "____________________________________________________________________________\n",
            "Power System Automation Laboratory    <>   phone office (409) 845-4623    \n",
            "Department of Electrical Engineering  <>   phone home   (409) 846-5850\n",
            "Texas A&M University                  <>   fax   (409) 862-2282\n",
            "College Station, TX 77843, USA        <>   Internet: avm1993@zeus.tamu.edu\n",
            "----------------------------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(open(data_dir / \"sci.electronics\" / \"53854\").read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpzFraz4wKhB",
        "outputId": "2d49fcc4-39ef-4263-eca0-6c9aec966754"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Newsgroups: comp.graphics\n",
            "Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!noc.near.net!howland.reston.ans.net!agate!dog.ee.lbl.gov!network.ucsd.edu!usc!rpi!nason110.its.rpi.edu!mabusj\n",
            "From: mabusj@nason110.its.rpi.edu (Jasen M. Mabus)\n",
            "Subject: Looking for Brain in CAD\n",
            "Message-ID: <c285m+p@rpi.edu>\n",
            "Nntp-Posting-Host: nason110.its.rpi.edu\n",
            "Reply-To: mabusj@rpi.edu\n",
            "Organization: Rensselaer Polytechnic Institute, Troy, NY.\n",
            "Date: Thu, 29 Apr 1993 23:27:20 GMT\n",
            "Lines: 7\n",
            "\n",
            "Jasen Mabus\n",
            "RPI student\n",
            "\n",
            "\tI am looking for a hman brain in any CAD (.dxf,.cad,.iges,.cgm,etc.) or picture (.gif,.jpg,.ras,etc.) format for an animation demonstration. If any has or knows of a location please reply by e-mail to mabusj@rpi.edu.\n",
            "\n",
            "Thank you in advance,\n",
            "Jasen Mabus  \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(open(data_dir / \"comp.graphics\" / \"38987\").read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT8d4GQuvJL5",
        "outputId": "69dc7951-9bb4-43db-bf5c-539a1968a1ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing alt.atheism, 1000 files found\n",
            "Processing comp.graphics, 1000 files found\n",
            "Processing comp.os.ms-windows.misc, 1000 files found\n",
            "Processing comp.sys.ibm.pc.hardware, 1000 files found\n",
            "Processing comp.sys.mac.hardware, 1000 files found\n",
            "Processing comp.windows.x, 1000 files found\n",
            "Processing misc.forsale, 1000 files found\n",
            "Processing rec.autos, 1000 files found\n",
            "Processing rec.motorcycles, 1000 files found\n",
            "Processing rec.sport.baseball, 1000 files found\n",
            "Processing rec.sport.hockey, 1000 files found\n",
            "Processing sci.crypt, 1000 files found\n",
            "Processing sci.electronics, 1000 files found\n",
            "Processing sci.med, 1000 files found\n",
            "Processing sci.space, 1000 files found\n",
            "Processing soc.religion.christian, 997 files found\n",
            "Processing talk.politics.guns, 1000 files found\n",
            "Processing talk.politics.mideast, 1000 files found\n",
            "Processing talk.politics.misc, 1000 files found\n",
            "Processing talk.religion.misc, 1000 files found\n",
            "Classes: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
            "Number of samples: 19997\n"
          ]
        }
      ],
      "source": [
        "# cleaning data and keeping whats needed\n",
        "samples = []\n",
        "labels = []\n",
        "class_names = []\n",
        "class_index = 0\n",
        "for dirname in sorted(os.listdir(data_dir)):\n",
        "    class_names.append(dirname)\n",
        "    dirpath = data_dir / dirname\n",
        "    fnames = os.listdir(dirpath)\n",
        "    print(\"Processing %s, %d files found\" % (dirname, len(fnames)))\n",
        "    for fname in fnames:\n",
        "        fpath = dirpath / fname\n",
        "        f = open(fpath, encoding=\"latin-1\")\n",
        "        content = f.read()\n",
        "        lines = content.split(\"\\n\")\n",
        "        lines = lines[10:]\n",
        "        content = \"\\n\".join(lines)\n",
        "        samples.append(content)\n",
        "        labels.append(class_index)\n",
        "    class_index += 1\n",
        "\n",
        "print(\"Classes:\", class_names)\n",
        "print(\"Number of samples:\", len(samples))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZZnfbi5w46M",
        "outputId": "491c8faa-a5e4-4b44-d769-bf8202de1d28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15998, 15998, 3999, 3999)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# shuffle data\n",
        "import numpy as np\n",
        "SEED=852\n",
        "rndsd = np.random.RandomState(SEED)\n",
        "rndsd.shuffle(samples)\n",
        "rndsd = np.random.RandomState(SEED)\n",
        "rndsd.shuffle(labels)\n",
        "\n",
        "# create train and validation splt\n",
        "SPLIT_SIZE=0.2\n",
        "sample_size = int(SPLIT_SIZE*len(samples))\n",
        "train_samples, train_labels, val_samples, val_labels = samples[:-sample_size],labels[:-sample_size],samples[-sample_size:],labels[-sample_size:]\n",
        "len(train_samples),len(train_labels),len(val_samples),len(val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "gDVoVSrKzWgm"
      },
      "outputs": [],
      "source": [
        "# TextVectorizer\n",
        "# finding vocab\n",
        "# TextVectorizer layer per avg vocab\n",
        "# fit to train text\n",
        "# test TextVectorizer\n",
        "# get unique #ofvocab get_vocabulary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNzFWaK3z6o-",
        "outputId": "4b4f7c40-cc28-41c2-9bf4-308a593a4570"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary:4255980\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "266"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "vocab = []\n",
        "for i in train_samples:\n",
        "  vocab.append(len(i.split()))\n",
        "print(f'Vocabulary:{sum(vocab)}')\n",
        "round(sum(vocab)/len(train_samples)) #avg length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "xbNEiM_f0Yjp"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 200\n",
        "MAX_VOCAB_LENGTH = 20000\n",
        "# create TextVectorizer\n",
        "text_vectorizer = keras.layers.TextVectorization(max_tokens=MAX_VOCAB_LENGTH,\n",
        "                                                 output_sequence_length=MAX_LENGTH)\n",
        "\n",
        "text_ds = tf_data.Dataset.from_tensor_slices(train_samples).batch(128).prefetch(tf_data.AUTOTUNE)\n",
        "\n",
        "# fit text vectorizer to train data\n",
        "text_vectorizer.adapt(text_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnxa5jlNRZxv",
        "outputId": "d2eb2ef7-aec4-4289-8719-000f92ec3b17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'to', 'of']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "text_vectorizer.get_vocabulary()[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtlQKVzu2bw_",
        "outputId": "1ce016c4-8d2b-4c7f-e11f-8b57672d36e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text Vectorized array is:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   2, 3469, 1742,   15,    2, 5899])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "# test text vectorizer\n",
        "vectorized_op = text_vectorizer([[\"the cat sat on the mat\"]])\n",
        "# print(f'Sample text:{rndsp}')\n",
        "print(f'\\nText Vectorized array is:')\n",
        "vectorized_op.numpy()[0,:6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "HxkOo3CZ2fPw"
      },
      "outputs": [],
      "source": [
        "# get_vocabulary\n",
        "voc = text_vectorizer.get_vocabulary()\n",
        "word_index = dict(zip(voc,range(len(voc))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ1fq8HeDTwq",
        "outputId": "a2638447-2ea2-4ee0-b53d-043199601b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "View first 5 vocab of train samples\n",
            "['', '[UNK]', 'the', 'to', 'of']\n",
            "View last 5 vocab of train samples\n",
            "['wedge', 'weavers', 'wdstarr', 'waycool', 'wavefunction']\n"
          ]
        }
      ],
      "source": [
        "print(f'View first 5 vocab of train samples\\n{voc[:5]}')\n",
        "print(f'View last 5 vocab of train samples\\n{voc[-5:]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TzdqLt_4Hcc",
        "outputId": "ca0650ee-4c36-45e0-b86b-416b5c602221"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total vocabulary:20000\n"
          ]
        }
      ],
      "source": [
        "print(f'Total vocabulary:{len(word_index)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
        "[word_index[w] for w in test]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcUwjWaG1AQ6",
        "outputId": "68754e5a-06fe-458e-ea18-467f890c99fd"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3469, 1742, 15, 2, 5899]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z19Ix4jE4VLC",
        "outputId": "8b81b9c7-26bc-4093-d112-48a8676a5823"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-18 17:45:35--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 38s  \n",
            "\n",
            "2024-03-18 17:48:14 (5.19 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# dowload Glove pre-trained word embedding\n",
        "!wget https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "CCghnKxGwa68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e55f31bb-7b96-4280-b90d-25b4cef7e392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of word vectors in 100Dim data:400000\n"
          ]
        }
      ],
      "source": [
        "#100dimesional text encoded vectors\n",
        "glvpth = \"glove.6B.100d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "word_lst = []\n",
        "coefs_lst = []\n",
        "with open(glvpth) as f:\n",
        "  for line in f:\n",
        "    word,coefs = line.split(maxsplit=1)\n",
        "    coefs = np.fromstring(coefs,\"f\",sep=\" \")\n",
        "    word_lst.append(word)\n",
        "    coefs_lst.append(coefs)\n",
        "    embeddings_index[word]=coefs\n",
        "\n",
        "print(f\"Total number of word vectors in 100Dim data:{len(embeddings_index)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "kiN8hEnJwuyA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7437b857-bb01-474c-a1b2-a1871d5095cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# embeddings_index[word_lst[0]],coefs_lst[0]\n",
        "np.array_equal(embeddings_index[word_lst[0]],coefs_lst[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "3X1uhVOUF2Oz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2733510b-d510-45a1-eec4-441f70581e13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conveted words:17976, skipped words:2024\n"
          ]
        }
      ],
      "source": [
        "num_tokens = len(voc) + 2\n",
        "embedding_dim = 100\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens,embedding_dim))\n",
        "# embedding_matrix.shape # (200002,100)\n",
        "for word,i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None: #words not found in embedding index will be all-zeros\n",
        "  #eg: padding of 0s, \"OOV\"\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "    hits += 1\n",
        "  else:\n",
        "    misses += 1\n",
        "print(f\"Conveted words:{hits}, skipped words:{misses}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Ux9SYJ3vSySs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80938cac-24cc-4e70-9073-f29404cf0212"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
              "       [-0.038194  , -0.24487001,  0.72812003, -0.39961001,  0.083172  ],\n",
              "       [-0.18970001,  0.050024  ,  0.19084001, -0.049184  , -0.089737  ],\n",
              "       [-0.1529    , -0.24279   ,  0.89837003,  0.16996001,  0.53516001]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "embedding_matrix[0:5,0:5] #view 1st 5 vectors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "IN3EIa5GELXA"
      },
      "outputs": [],
      "source": [
        "# Create embedding\n",
        "# keras.layers.Embedding\n",
        "# size of vocab\n",
        "# output dim\n",
        "# trainable=False if using pre-trained Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "1wy2mC25FEKF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3a56ea6-ef44-4b75-a414-19bb96ab809f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inital weights:[]\n",
            "Set weights:[array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
            "         0.      ],\n",
            "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
            "         0.      ],\n",
            "       [-0.038194, -0.24487 ,  0.72812 , ..., -0.1459  ,  0.8278  ,\n",
            "         0.27062 ],\n",
            "       ...,\n",
            "       [ 0.6617  ,  0.31339 ,  0.60506 , ...,  0.25023 , -0.17894 ,\n",
            "        -0.42512 ],\n",
            "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
            "         0.      ],\n",
            "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
            "         0.      ]], dtype=float32)]\n"
          ]
        }
      ],
      "source": [
        "# create embedding\n",
        "embedding_layer = keras.layers.Embedding(num_tokens,\n",
        "                                         embedding_dim,\n",
        "                                         trainable=False)\n",
        "\n",
        "print(f'Inital weights:{embedding_layer.get_weights()}')\n",
        "embedding_layer.build((1,))\n",
        "embedding_layer.set_weights([embedding_matrix])\n",
        "print(f'Set weights:{embedding_layer.get_weights()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUNhojnvGvlr"
      },
      "source": [
        "## Conv1D using pre-trained embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKUllxBtzmMX",
        "outputId": "ac617cc9-69ce-44f8-9a46-a11815e1b1bf"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "AgsyeTWbPs5B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a92f84b-6e67-48e6-e13b-49cd4b9d11fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Glove_embd_Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, None, 100)         2000200   \n",
            "                                                                 \n",
            " conv1d_17 (Conv1D)          (None, None, 128)         64128     \n",
            "                                                                 \n",
            " average_pooling1d_10 (Aver  (None, None, 128)         0         \n",
            " agePooling1D)                                                   \n",
            "                                                                 \n",
            " conv1d_18 (Conv1D)          (None, None, 128)         82048     \n",
            "                                                                 \n",
            " average_pooling1d_11 (Aver  (None, None, 128)         0         \n",
            " agePooling1D)                                                   \n",
            "                                                                 \n",
            " conv1d_19 (Conv1D)          (None, None, 128)         82048     \n",
            "                                                                 \n",
            " global_average_pooling1d_5  (None, 128)               0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 20)                2580      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2247516 (8.57 MB)\n",
            "Trainable params: 247316 (966.08 KB)\n",
            "Non-trainable params: 2000200 (7.63 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "seq_inputs = keras.Input(shape=(None,),dtype=tf.float32) # passing textVectorizer op\n",
        "embedded_sequences = embedding_layer(seq_inputs) #embedding layer o/p\n",
        "#build model\n",
        "x = keras.layers.Conv1D(128,5,activation=\"relu\",padding=\"valid\")(embedded_sequences)\n",
        "x = keras.layers.AveragePooling1D()(x)\n",
        "x = keras.layers.Conv1D(128,5,activation=\"relu\")(x)\n",
        "x = keras.layers.AveragePooling1D()(x)\n",
        "x = keras.layers.Conv1D(128,5,activation=\"relu\")(x)\n",
        "x = keras.layers.GlobalAveragePooling1D()(x)\n",
        "x = keras.layers.Dense(128,activation=\"relu\")(x)\n",
        "x = keras.layers.Dropout(0.5)(x) # to avoid overfitting\n",
        "outputs = keras.layers.Dense(len(class_names),activation=\"softmax\")(x) #multiclass classification\n",
        "glv_embd_cnv_model = keras.Model(seq_inputs,outputs,name=\"Glove_embd_Conv1D\")\n",
        "glv_embd_cnv_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "nYu2qKftXHg4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe2f3e9b-8e86-4464-9a0a-174e1f1cbeff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, int)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "type(train_samples), type(train_labels[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "s045IDlWymLn"
      },
      "outputs": [],
      "source": [
        "# converting string to numpy arrays\n",
        "arr_str_smpls = []\n",
        "for s in train_samples:\n",
        "  arr_str_smpls.append(np.array(s))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "oUBXfaKrzjj2"
      },
      "outputs": [],
      "source": [
        "# converting string to numpy arrays\n",
        "arr_str_val_smpls = []\n",
        "for s in val_samples:\n",
        "  arr_str_val_smpls.append(np.array(s))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "mi8q__ZYPmrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12e0c8c7-16db-4b27-9ea3-9458dacf9433"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15998, 3999, 15998, 3999)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# converting string to numpy arrays\n",
        "X_train = text_vectorizer(arr_str_smpls).numpy()\n",
        "X_val = text_vectorizer(arr_str_val_smpls).numpy()\n",
        "\n",
        "y_train = np.array(train_labels) #labels\n",
        "y_val = np.array(val_samples)\n",
        "\n",
        "len(X_train),len(X_val), len(y_train), len(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "0gA24qi3KKsd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89eb241c-0360-4e10-eba1-3d34f7e011d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((15998, 200), (15998,), (3999, 200), (3999,))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.expand_dims(y_train,axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqsrG17uwt0x",
        "outputId": "98d17de3-712a-42e6-89b5-31be8123adc3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15998), dtype=int64, numpy=array([[ 1,  2,  9, ..., 15,  1,  3]])>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FasAMXYFx52N",
        "outputId": "da2148f7-1d02-4bac-9c55-57083d9573f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "125/125 [==============================] - ETA: 0s - loss: 2.6788 - acc: 0.1370"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnimplementedError",
          "evalue": "Graph execution error:\n\nDetected at node Cast_1 defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-56-0b961a2de77a>\", line 5, in <cell line: 5>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1856, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2296, in evaluate\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 4108, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2066, in test_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2049, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2037, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1920, in test_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1249, in compute_metrics\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 620, in update_state\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/metrics/base_metric.py\", line 708, in update_state\n\n2 root error(s) found.\n  (0) UNIMPLEMENTED:  Cast string to float is not supported\n\t [[{{node Cast_1}}]]\n  (1) CANCELLED:  Function was cancelled before it was started\n0 successful operations.\n0 derived errors ignored. [Op:__inference_test_function_32079]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-0b961a2de77a>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# rmsprop works better than Adam w/ sparse crossentropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mglv_embd_cnv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node Cast_1 defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-56-0b961a2de77a>\", line 5, in <cell line: 5>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1856, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2296, in evaluate\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 4108, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2066, in test_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2049, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2037, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1920, in test_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1249, in compute_metrics\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 620, in update_state\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/metrics/base_metric.py\", line 708, in update_state\n\n2 root error(s) found.\n  (0) UNIMPLEMENTED:  Cast string to float is not supported\n\t [[{{node Cast_1}}]]\n  (1) CANCELLED:  Function was cancelled before it was started\n0 successful operations.\n0 derived errors ignored. [Op:__inference_test_function_32079]"
          ]
        }
      ],
      "source": [
        "# compile model\n",
        "glv_embd_cnv_model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"rmsprop\",metrics=[\"acc\"])\n",
        "# rmsprop works better than Adam w/ sparse crossentropy\n",
        "# fit model\n",
        "glv_embd_cnv_model.fit(X_train,y_train, batch_size=128,epochs=20,validation_data=(X_val,y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using Tensorflow Hub pre-trained word embedding: USE,BERT"
      ],
      "metadata": {
        "id": "sT8Sv2Up-iZ6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0XKYT4rAxeiJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3545cfc1-e74f-4aa9-9f37-1cd42b06a634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-20 23:07:09--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.174.207, 74.125.23.207, 74.125.203.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.174.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "nlp_getting_started 100%[===================>] 593.11K   986KB/s    in 0.6s    \n",
            "\n",
            "2024-03-20 23:07:10 (986 KB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Get text dataset from Kaggle\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "hf.unzip_data(\"nlp_getting_started.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "#shuffle train data\n",
        "train_df = train_df.sample(frac=1,random_state=852)\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6ChxcTMy_ZZS",
        "outputId": "4caaa702-c49a-40f2-897f-f0a4de6b648c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id               keyword             location  \\\n",
              "7561  10810               wrecked                    6   \n",
              "5421   7737             panicking                  NaN   \n",
              "6338   9060  structural%20failure        San Francisco   \n",
              "5509   7862           quarantined            Melbourne   \n",
              "6819   9766               trapped  central chazifornia   \n",
              "\n",
              "                                                   text  target  \n",
              "7561                      @Tunes_WGG lol. U got wrecked       0  \n",
              "5421  When he lets you drive his truck and you start...       0  \n",
              "6338  [CLIP] Top-down coercion - The structural weak...       0  \n",
              "5509  #hot  Reddit's new content policy goes into ef...       1  \n",
              "6819  salute to all the kids still trapped in adult ...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e55f63e-ab4a-4df8-912d-748ef76eb3c9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7561</th>\n",
              "      <td>10810</td>\n",
              "      <td>wrecked</td>\n",
              "      <td>6</td>\n",
              "      <td>@Tunes_WGG lol. U got wrecked</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5421</th>\n",
              "      <td>7737</td>\n",
              "      <td>panicking</td>\n",
              "      <td>NaN</td>\n",
              "      <td>When he lets you drive his truck and you start...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6338</th>\n",
              "      <td>9060</td>\n",
              "      <td>structural%20failure</td>\n",
              "      <td>San Francisco</td>\n",
              "      <td>[CLIP] Top-down coercion - The structural weak...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5509</th>\n",
              "      <td>7862</td>\n",
              "      <td>quarantined</td>\n",
              "      <td>Melbourne</td>\n",
              "      <td>#hot  Reddit's new content policy goes into ef...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6819</th>\n",
              "      <td>9766</td>\n",
              "      <td>trapped</td>\n",
              "      <td>central chazifornia</td>\n",
              "      <td>salute to all the kids still trapped in adult ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e55f63e-ab4a-4df8-912d-748ef76eb3c9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2e55f63e-ab4a-4df8-912d-748ef76eb3c9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2e55f63e-ab4a-4df8-912d-748ef76eb3c9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-117c9876-0323-46a2-abff-e167d504e81a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-117c9876-0323-46a2-abff-e167d504e81a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-117c9876-0323-46a2-abff-e167d504e81a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 7613,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3137,\n        \"min\": 1,\n        \"max\": 10873,\n        \"num_unique_values\": 7613,\n        \"samples\": [\n          1495,\n          10382,\n          8920\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keyword\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 221,\n        \"samples\": [\n          \"refugees\",\n          \"blight\",\n          \"evacuated\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3341,\n        \"samples\": [\n          \"Njoro, Kenya\",\n          \"UGA '15 Alumnus - Economics \",\n          \"570 Vanderbilt; Brooklyn, NY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7503,\n        \"samples\": [\n          \"Flooding kills 166 displace over one million in Pakistan http://t.co/iCFQl7I9oP\\n\\nAt least 166 people have been killed and nearly 11 lakh\\u0089\\u00db_\",\n          \"I feel like I should be panicking more as Idk I get my results back in a week... I'm Alarmingly calm\",\n          \"I will adamantly opposed to nuclear weapons.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split data\n",
        "train_sentences, val_sentences, train_labels,val_labels = train_test_split(train_df[\"text\"].to_numpy(),\n",
        "                                                                           train_df[\"target\"].to_numpy(),\n",
        "                                                                           test_size=0.1,\n",
        "                                                                           random_state=852)\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g6hmJhCATn7",
        "outputId": "6c493e39-7195-4648-8861-01c26c38e8cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "for i in train_sentences:\n",
        "  words.append(len(i.split()))\n",
        "print(f'Total number of words:{sum(words)},\\nAvg length of a word:{round(sum(words)/len(train_sentences))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zE40xoKBbDb",
        "outputId": "4879635e-1fea-4df4-a48f-ab9f7581846f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of words:102030,\n",
            "Avg length of a word:15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Vectorization\n",
        "MAX_VOCAB_LENGTH = 10000\n",
        "MAX_LENGTH = 15\n",
        "text_vectorizer = keras.layers.TextVectorization(max_tokens=MAX_VOCAB_LENGTH,\n",
        "                                                 output_mode=\"int\",\n",
        "                                                 output_sequence_length=MAX_LENGTH)\n",
        "#fit to train data\n",
        "text_vectorizer.adapt(train_sentences)\n",
        "\n",
        "#get_vocab\n",
        "vocab = text_vectorizer.get_vocabulary()\n",
        "vocab[-5:] #last 5 common words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqPYyOfr_pTP",
        "outputId": "618d6aa1-f00a-4837-e0f9-b28c931a3157"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pageparkescorp', 'pagasa', 'padres', 'paddytomlinson1', 'padded']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base model Naive Bayes"
      ],
      "metadata": {
        "id": "R_yIm8qaDbcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create model\n",
        "base_model = Pipeline([\n",
        "    (\"tfidf\",TfidfVectorizer()),\n",
        "    (\"clf\",MultinomialNB),\n",
        "])\n",
        "\n",
        "# fit model\n",
        "base_model.fit(train_sentences,train_labels)"
      ],
      "metadata": {
        "id": "Lg56aJAhEIHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub"
      ],
      "metadata": {
        "id": "wdXODO_pFc9r"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## USE, BRT"
      ],
      "metadata": {
        "id": "fNJvgeNCPG_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample sentences\n",
        "feed_sentneces = [\"Who let the dogs out!\",\n",
        "                  \"I will pass Tensorflow Certification exam\",\n",
        "                  \"I will create GymFriend, an RAG-LLM for working out from rut\",\n",
        "                  random.choice(train_sentences)]\n",
        "\n",
        "# load pre-processing models and BERT\n",
        "preprocess = hub.load('https://kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-uncased-preprocess/versions/3')\n",
        "bert = hub.load('https://www.kaggle.com/models/google/experts-bert/frameworks/TensorFlow2/variations/pubmed/versions/2')"
      ],
      "metadata": {
        "id": "d6fzOjnUGpSh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "👀"
      ],
      "metadata": {
        "id": "_qRyq08B8BET"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "`RuntimeError: Op type not registered 'CaseFoldUTF8' in binary running on d9dcdc0ab727. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib (e.g. `tf.contrib.resampler`), accessing should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`"
      ],
      "metadata": {
        "id": "LnTkKvB6IksU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list -v | grep h5py #confirm h5py is installed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ5fHShS_-uC",
        "outputId": "72a7c57b-c297-4761-eb69-e0dbb5822617"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h5py                             3.10.0                /usr/local/lib/python3.10/dist-packages pip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess bert inputs\n",
        "bert_inputs = preprocess(feed_sentneces)\n",
        "pooled_op = bert(bert_inputs)[\"pooled_output\"]\n",
        "print(pooled_op)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40PHtT_88Aqk",
        "outputId": "f6700c93-8bef-4924-9ae9-776006f62e79"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.5575614  -0.7712987   0.47441086 ... -0.5017476   0.05907806\n",
            "   0.20602828]\n",
            " [-0.1782388  -0.74593055  0.24996322 ... -0.01832353 -0.7063562\n",
            "  -0.32982334]\n",
            " [-0.6880345  -0.70190215  0.7147866  ...  0.561458    0.13850242\n",
            "   0.3187623 ]\n",
            " [-0.81527066 -0.737917    0.8383408  ...  0.5470424  -0.155741\n",
            "  -0.46082312]], shape=(4, 768), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(bert_inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZaFERrK83Ju",
        "outputId": "09c5869c-eec9-4af5-bdc9-12b1d976aca6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(bert_inputs.values())[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oh322sEzBT0Z",
        "outputId": "5c17dc50-78b7-4aa2-e40c-d98919c857fb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT pre-process layer\n",
        "bert_preprocess_model = hub.KerasLayer(\"https://kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-uncased-preprocess/versions/3\",\n",
        "                                       name=\"BERT_preprocess\")"
      ],
      "metadata": {
        "id": "CzN0ZExsOhll"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Keras layer of pretrained BERT embedding using hub.KerasLayer\n",
        "bert_layer = hub.KerasLayer(\"https://www.kaggle.com/models/google/experts-bert/frameworks/TensorFlow2/variations/pubmed/versions/2\",\n",
        "                            input_shape=[],\n",
        "                            dtype=tf.string,\n",
        "                            name=\"BERT\")"
      ],
      "metadata": {
        "id": "UYWw5NCVBzGT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing text\n",
        "text_preprocessed = bert_preprocess_model(feed_sentneces)\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kG4dg8rO7C7",
        "outputId": "c8af87d3-4cf8-4c93-8d02-adc07dbcaffb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys       : ['input_word_ids', 'input_mask', 'input_type_ids']\n",
            "Shape      : (4, 128)\n",
            "Word Ids   : [ 101 2040 2292 1996 6077 2041  999  102    0    0    0    0]\n",
            "Input Mask : [1 1 1 1 1 1 1 1 0 0 0 0]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Passing text to BERT\n",
        "bert_results = bert_layer(text_preprocessed)\n",
        "#pooled_output array is focus=> embedding for whole tweet\n",
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQKbytOVPqUL",
        "outputId": "9a6886e4-61fd-48ef-c9f6-eaa735bd769b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pooled Outputs Shape:(4, 768)\n",
            "Pooled Outputs Values:[ 0.5575614  -0.7712987   0.47441086 -0.9046864  -0.28607187 -0.3575559\n",
            " -0.30507597  0.9237328   0.7350716  -0.53716934  0.71425474 -0.04365641]\n",
            "Sequence Outputs Shape:(4, 128, 768)\n",
            "Sequence Outputs Values:[[ 0.6292875  -1.0235257   0.515747   ... -0.551639    0.05914694\n",
            "   0.20902002]\n",
            " [ 0.89913094 -0.69259846  1.586041   ... -0.0398142   0.44479248\n",
            "  -1.7413702 ]\n",
            " [ 0.7524595  -1.823583    1.3761601  ... -0.3539341   0.10428149\n",
            "  -0.2983049 ]\n",
            " ...\n",
            " [ 0.9477291  -2.5717602   1.2198112  ... -0.07271172  0.7514439\n",
            "   1.1387274 ]\n",
            " [ 0.87541854 -2.3192284   1.4144423  ... -0.07104795  0.7416128\n",
            "   0.78527474]\n",
            " [ 1.0096389  -2.2561433   1.3331144  ... -0.22646064  0.522534\n",
            "   0.8222622 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create model using BERT embedding with Functional API\n",
        "inputs = keras.layers.Input(shape=(),dtype=tf.string)\n",
        "x = bert_preprocess_model(inputs) #Pre-process model\n",
        "x = bert_layer(x) #BERT layer\n",
        "x = keras.layers.Dense(128,activation=\"relu\")(x['pooled_output']) # bert_op['pooled_output'] =>embedding\n",
        "x = keras.layers.Dropout(0.1)(x)\n",
        "outputs = keras.layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "BERT_embedded_model = keras.Model(inputs,outputs,name=\"BERT_feature_extractor\")\n",
        "\n",
        "# compile model\n",
        "BERT_embedded_model.compile(loss=\"binary_crossentropy\",\n",
        "                            optimizer=keras.optimizers.Adam(),\n",
        "                            metrics=[\"accuracy\"])\n",
        "\n",
        "#model summary\n",
        "BERT_embedded_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf7JQmQgDguT",
        "outputId": "f0a5a60d-ba8e-4a73-868d-f119b029a2ba"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"BERT_feature_extractor\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)        [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " BERT_preprocess (KerasLaye  {'input_word_ids': (None,    0         ['input_4[0][0]']             \n",
            " r)                          128),                                                                \n",
            "                              'input_mask': (None, 128)                                           \n",
            "                             , 'input_type_ids': (None,                                           \n",
            "                              128)}                                                               \n",
            "                                                                                                  \n",
            " BERT (KerasLayer)           {'pooled_output': (None, 7   1094822   ['BERT_preprocess[3][0]',     \n",
            "                             68),                         41         'BERT_preprocess[3][1]',     \n",
            "                              'sequence_output': (None,              'BERT_preprocess[3][2]']     \n",
            "                              128, 768),                                                          \n",
            "                              'encoder_outputs': [(None                                           \n",
            "                             , 128, 768),                                                         \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768)],                                                  \n",
            "                              'default': (None, 768)}                                             \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 128)                  98432     ['BERT[3][13]']               \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 128)                  0         ['dense_7[0][0]']             \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 1)                    129       ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109580802 (418.02 MB)\n",
            "Trainable params: 98561 (385.00 KB)\n",
            "Non-trainable params: 109482241 (417.64 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fit model #run with GPU enable only\n",
        "BERT_embedded_model_history = BERT_embedded_model.fit(train_sentences,\n",
        "                        train_labels,\n",
        "                        epochs=5,\n",
        "                        verbose=0,\n",
        "                        validation_data=(val_sentences,val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "X2LOu71bFpBS",
        "outputId": "55137d96-97a3-4f03-994a-a676fee20d9d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-ab118e93e76c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m BERT_embedded_model_history = BERT_embedded_model.fit(train_sentences,\n\u001b[0m\u001b[1;32m      3\u001b[0m                         \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1802\u001b[0m                         ):\n\u001b[1;32m   1803\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1804\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1805\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    870\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1501\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPL45t2+yTzQVx/4rT3z2dO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}